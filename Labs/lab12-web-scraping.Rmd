---
title: "Lab 12: Getting Started with Web Scraping"
subtitle: "Stat 133, Spring 2018"
author: "Kanak Garg"
output: html_document
---

> ### Learning Objectives
>
> - Work with the package `"rvest"`
> - Learn to extract html elements and attributes
> - Create a simple crawler

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.path = 'lab12-images/')
library(XML)
library(xml2)
library(rvest)
library(stringr)
library(magrittr)
```

------

## Required Packages

In this lab, you will have to load the following R packages:

```{r eval = FALSE}
library(XML)
library(xml2)
library(rvest)
library(magrittr)
```


## Motivation

```{r eval = FALSE}
# Assemble url (so it fits on screen)
basket <- "https://www.basketball-reference.com"
gsw <- "/teams/GSW/2017.html"
gsw_url <- paste0(basket, gsw)

# download HTML file to your working directory
download.file(gsw_url, 'gsw-roster-2017.html')

# Read GSW Roster html table
gsw_roster <- readHTMLTable('gsw-roster-2017.html')
```


```{r echo = FALSE}
gsw_roster <- readHTMLTable('../data/gsw-roster-2017.html')
gsw_roster
```


### Roster tables

Say you are interested in obtaining the Roster table for the Boston Celtics (BOS).
You could get such table by adapting the code used to get the GSW roster. The
only thing you need to change is the team abbreviation from `GSW` to `BOS`:

```{r eval = FALSE}
# Assemble url (so it fits on screen)
basket <- "https://www.basketball-reference.com"
bos <- "/teams/BOS/2017.html"
bos_url <- paste0(basket, bos)

# download HTML file to your working directory
download.file(bos_url, 'bos-roster-2017.html')

# Read BOS Roster html table
bos_roster <- readHTMLTable('bos-roster-2017.html')
```

In order to get the Roster tables of all the NBA teams, you would need to 
repeat the same operation with the corresponding team abbreviations. But how
do you get these abbreviations in a programmatic way?

## Extracting HTML elements

```{r echo = FALSE}
xml_doc <- read_html('../data/nba2017-conference-standings.html')
```

So how do we extract these `href` attributes? The first step is to read the 
contents of the html file:

https://www.basketball-reference.com/leagues/NBA_2017.html

This can be done with the function `read_html()`

```{r eval = FALSE}
nba_html <- paste0(basket, "/leagues/NBA_2017.html")

xml_doc <- read_html(nba_html)
```

The object `xml_doc` is an object of class `"xml_document"`. If you are 
curious about extracting all the content in a character vector, then use 
the function `html_text()`, chained with the pipe `%>%` operator:

```{r eval = FALSE}
xml_text <- xml_doc %>% html_text()
```

The object `xml_text` is a character vector that contains the content of 
the html file.


### Extracting elements `h2`

Before attempting extracting the href attributes, let's begin with something
simpler. For example, let's see how to extract the value of all the HTML elements __h2__ 
(i.e. headings of level 2). This can be done with the function `html_nodes()`, 
and then `html_text()`

```{r}
# content of h2 nodes
xml_doc %>%
  html_nodes("h2") %>%
  html_text() 
```

You can pass the name of an HTML element (i.e. a tag or node) to `html_nodes()`.
In this case, we indicate that we want to locate the nodes `"h2"`. And then
we call `html_text()` to _extract_ the actual content in those nodes.


### Your turn

Use `html_nodes()` and `html_text()` to extract the values of nodes:

- `"h1"`

```{r}
# content of h2 nodes
xml_doc %>%
  html_nodes("h1") %>%
  html_text() 
```
- `"strong"`
```{r}
# content of h2 nodes
xml_doc %>%
  html_nodes("strong") %>%
  html_text() 
```
- `"button"`
```{r}
# content of h2 nodes
xml_doc %>%
  html_nodes("button") %>%
  html_text() 
```
-----




```{r}
# node with an attribute
xml_doc %>%
  html_nodes("p.listhead") %>%
  html_text()
```


## XPath

In order to specify HTML elements that are embeded inside other HTML elements,
you need to use __XPaths__. 

XPath expressions have a syntax similar to the way files are located in a 
hierarchy of directories/folders in a computer file system. To be more precise,
Xpath expressions allow you to indicate the 
specific _path_ that must be taken to arrive at a given node.

In general, we can specify paths through the tree structure:

- based on node names
- based on node content
- based on a node's relationship to other nodes

| Symbol  | Description                |
|---------|----------------------------|
|  `/`    | selects from the root node |
|  `//`   | selects nodes anywhere     |
|  `.`    | selects the current node   |
|  `..`   | Selects the parent of the current node |
|  `@`    | Selects attributes         |
|  `[]`   | Square brackets to indicate attributes |


Let's go back to the `p.listhead` nodes. These can be extracted with an Xpath expression like this:

```{r}
xml_doc %>%
  html_nodes(xpath = '//p[@class="listhead"]') %>%
  html_text()
```

The XPath `'//p[@class="listhead"]'` means that we want to locate, anywhere in 
the tree (`//`), all `<p>` nodes that have an attribute named `class` that 
takes the value `"listhead"`.

What if you want to extract the `<a>` values inside the listed items `<li>`, 
within the unlisted list `<ul>`?

```{r}
xml_doc %>%
  html_nodes(xpath = '//ul[@class=""]/li/a') %>%
  html_text()
```

or equivalently:

```{r}
xml_doc %>%
  html_nodes(xpath = '//ul[@class=""]//a') %>%
  html_text()
```


## Extracting `href` attributes

Let's focus again on the first two html tables of the page
https://www.basketball-reference.com/leagues/NBA_2017.html.

To extract the first `"table"` you can use `html_nodes()` and `extract()` as follows:

```{r}
# extracting first table 
xml_table1 <- xml_doc %>%
  html_nodes("table") %>%
  extract(1)

class(xml_table1)
```

The object `xml_table1` is not really an R table, but an object of class 
`xml_nodeset`. To extract the html table as a data frame, `"rvest"` provides 
the function `html_table()`:

```{r}
tbl1 <- html_table(xml_table1)

head(tbl1)
```


Likewise, the second html table can be extracted (as an `xml_nodeset`) in the following way:

```{r}
# extracting second table 
xml_table2 <- xml_doc %>%
  html_nodes("table") %>%
  extract(2)
```

Actually, both tables can be extracted simultaneously:

```{r}
# two html tables
xml_tables <- xml_doc %>%
  html_nodes("table") %>%
  extract(1:2)
```

Having extracted the tables we are interested in, we can select the `<a>` nodes, and then extract the content that corresponds to the name of the teams:

```{r}
# extract names of teams
xml_tables %>% 
  html_nodes("a") %>%
  html_text()
```

In order to get the `href` attributes we need to use the `html_attr()` function:

```{r}
# href attributes
xml_tables %>% 
  html_nodes("a") %>%
  html_attr("href")
```

Bingo!!!


-----


## Your turn
```{r}
hrefs <- xml_tables %>% 
  html_nodes("a") %>%
  html_attr("href")

teams <- 1:length(hrefs)
for (i in teams){
  val <- str_split_fixed(hrefs[i], "/", 4)[3]
  teams[i] <- val
}
```

```{r}
files <- str_c(teams, "-roster-2017.csv")

```

- Use the object `basket` and the first element of `hrefs` (i.e. `hrefs[1]`) to 
assemble a `team_url` like the one used for `gsw_url`:
```
# modify with `hrefs[1]`

gsw <- "/teams/GSW/2017.html"
gsw_url <- paste0(basket, gsw)
```
```{r}
basket <- "https://www.basketball-reference.com"
team_url <- str_c(basket, hrefs)
```



